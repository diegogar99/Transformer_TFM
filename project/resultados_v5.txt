embedding_dim = 256              
context_len = 128
num_epochs = 20
patience_limit = 10 # Para early stopping
num_layers = 3
num_heads = 8
d_ff = 1024
dropout = 0.3
optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)
scheduler = LambdaLR(optimizer, lr_lambda) en cada epoch


GPU available: True
Carga datasets
	Tiny Shakespeare
	Wikitext-2
Longitud corpus train: 896135 caracteres
Longitud corpus valid: 100448 caracteres
Longitud corpus test: 111570 caracteres
Tokenización del corpus de train, test y validation
Número total de tokens en el corpus: 273905
Tokenización del corpus de train, test y validation
Número total de tokens en el corpus: 31059
Preparando DataLoader
Se invoca el modelo
TRAIN
Iteracciones: 4278
  [Batch 100] Loss: 9.3812
  [Batch 200] Loss: 9.3750
  [Batch 300] Loss: 9.3881
  [Batch 400] Loss: 9.3724
  [Batch 500] Loss: 9.3762
  [Batch 600] Loss: 9.3702
  [Batch 700] Loss: 9.3671
  [Batch 800] Loss: 9.3717
  [Batch 900] Loss: 9.3680
  [Batch 1000] Loss: 9.3622
  [Batch 1100] Loss: 9.3554
  [Batch 1200] Loss: 9.3663
  [Batch 1300] Loss: 9.3658
  [Batch 1400] Loss: 9.3569
  [Batch 1500] Loss: 9.3633
  [Batch 1600] Loss: 9.3587
  [Batch 1700] Loss: 9.3521
  [Batch 1800] Loss: 9.3498
  [Batch 1900] Loss: 9.3487
  [Batch 2000] Loss: 9.3425
  [Batch 2100] Loss: 9.3487
  [Batch 2200] Loss: 9.3502
  [Batch 2300] Loss: 9.3515
  [Batch 2400] Loss: 9.3476
  [Batch 2500] Loss: 9.3506
  [Batch 2600] Loss: 9.3427
  [Batch 2700] Loss: 9.3423
  [Batch 2800] Loss: 9.3272
  [Batch 2900] Loss: 9.3458
  [Batch 3000] Loss: 9.3334
  [Batch 3100] Loss: 9.3400
  [Batch 3200] Loss: 9.3326
  [Batch 3300] Loss: 9.3318
  [Batch 3400] Loss: 9.3255
  [Batch 3500] Loss: 9.3224
  [Batch 3600] Loss: 9.3200
  [Batch 3700] Loss: 9.3245
  [Batch 3800] Loss: 9.3228
  [Batch 3900] Loss: 9.3112
  [Batch 4000] Loss: 9.3107
  [Batch 4100] Loss: 9.3169
  [Batch 4200] Loss: 9.3218
[Epoch 1] Train Loss: 9.3486 | Train PPL: 11482.22 | Val PPL: 11026.96
Iteracciones: 4278
  [Batch 100] Loss: 9.3001
  [Batch 200] Loss: 9.3077
  [Batch 300] Loss: 9.2954
  [Batch 400] Loss: 9.3095
  [Batch 500] Loss: 9.3082
  [Batch 600] Loss: 9.2993
  [Batch 700] Loss: 9.3076
  [Batch 800] Loss: 9.2920
  [Batch 900] Loss: 9.2717
  [Batch 1000] Loss: 9.2808
  [Batch 1100] Loss: 9.2841
  [Batch 1200] Loss: 9.2714
  [Batch 1300] Loss: 9.2734
  [Batch 1400] Loss: 9.2683
  [Batch 1500] Loss: 9.2644
  [Batch 1600] Loss: 9.2662
  [Batch 1700] Loss: 9.2668
  [Batch 1800] Loss: 9.2546
  [Batch 1900] Loss: 9.2548
  [Batch 2000] Loss: 9.2539
  [Batch 2100] Loss: 9.2598
  [Batch 2200] Loss: 9.2430
  [Batch 2300] Loss: 9.2414
  [Batch 2400] Loss: 9.2412
  [Batch 2500] Loss: 9.2236
  [Batch 2600] Loss: 9.2318
  [Batch 2700] Loss: 9.2239
  [Batch 2800] Loss: 9.2232
  [Batch 2900] Loss: 9.2187
  [Batch 3000] Loss: 9.2148
  [Batch 3100] Loss: 9.1964
  [Batch 3200] Loss: 9.2083
  [Batch 3300] Loss: 9.2139
  [Batch 3400] Loss: 9.1889
  [Batch 3500] Loss: 9.1969
  [Batch 3600] Loss: 9.1967
  [Batch 3700] Loss: 9.1856
  [Batch 3800] Loss: 9.1834
  [Batch 3900] Loss: 9.1846
  [Batch 4000] Loss: 9.1802
  [Batch 4100] Loss: 9.1784
  [Batch 4200] Loss: 9.1597
[Epoch 2] Train Loss: 9.2431 | Train PPL: 10333.15 | Val PPL: 9575.47
Iteracciones: 4278
  [Batch 100] Loss: 9.1642
  [Batch 200] Loss: 9.1616
  [Batch 300] Loss: 9.1535
  [Batch 400] Loss: 9.1467
  [Batch 500] Loss: 9.1395
  [Batch 600] Loss: 9.1308
  [Batch 700] Loss: 9.1128
  [Batch 800] Loss: 9.0985
  [Batch 900] Loss: 9.1162
  [Batch 1000] Loss: 9.1042
  [Batch 1100] Loss: 9.0886
  [Batch 1200] Loss: 9.1000
  [Batch 1300] Loss: 9.0864
  [Batch 1400] Loss: 9.0771
  [Batch 1500] Loss: 9.0539
  [Batch 1600] Loss: 9.0621
  [Batch 1700] Loss: 9.0488
  [Batch 1800] Loss: 9.0443
  [Batch 1900] Loss: 9.0472
  [Batch 2000] Loss: 9.0468
  [Batch 2100] Loss: 9.0300
  [Batch 2200] Loss: 9.0188
  [Batch 2300] Loss: 9.0285
  [Batch 2400] Loss: 9.0017
  [Batch 2500] Loss: 8.9921
  [Batch 2600] Loss: 8.9973
  [Batch 2700] Loss: 8.9772
  [Batch 2800] Loss: 8.9708
  [Batch 2900] Loss: 8.9658
  [Batch 3000] Loss: 8.9548
  [Batch 3100] Loss: 8.9510
  [Batch 3200] Loss: 8.9425
  [Batch 3300] Loss: 8.9299
  [Batch 3400] Loss: 8.9231
  [Batch 3500] Loss: 8.9160
  [Batch 3600] Loss: 8.9056
  [Batch 3700] Loss: 8.9014
  [Batch 3800] Loss: 8.9019
  [Batch 3900] Loss: 8.9012
  [Batch 4000] Loss: 8.8758
  [Batch 4100] Loss: 8.8603
  [Batch 4200] Loss: 8.8602
[Epoch 3] Train Loss: 9.0199 | Train PPL: 8265.92 | Val PPL: 7066.42
Iteracciones: 4278
  [Batch 100] Loss: 8.8475
  [Batch 200] Loss: 8.8139
  [Batch 300] Loss: 8.8144
  [Batch 400] Loss: 8.8035
  [Batch 500] Loss: 8.7992
  [Batch 600] Loss: 8.7767
  [Batch 700] Loss: 8.7606
  [Batch 800] Loss: 8.7530
  [Batch 900] Loss: 8.7374
  [Batch 1000] Loss: 8.7253
  [Batch 1100] Loss: 8.7032
  [Batch 1200] Loss: 8.7048
  [Batch 1300] Loss: 8.6968
  [Batch 1400] Loss: 8.6778
  [Batch 1500] Loss: 8.6409
  [Batch 1600] Loss: 8.6538
  [Batch 1700] Loss: 8.6322
  [Batch 1800] Loss: 8.6269
  [Batch 1900] Loss: 8.6133
  [Batch 2000] Loss: 8.6034
  [Batch 2100] Loss: 8.5510
  [Batch 2200] Loss: 8.5443
  [Batch 2300] Loss: 8.5586
  [Batch 2400] Loss: 8.5433
  [Batch 2500] Loss: 8.4969
  [Batch 2600] Loss: 8.5219
  [Batch 2700] Loss: 8.4921
  [Batch 2800] Loss: 8.4561
  [Batch 2900] Loss: 8.4485
  [Batch 3000] Loss: 8.4399
  [Batch 3100] Loss: 8.4148
  [Batch 3200] Loss: 8.3800
  [Batch 3300] Loss: 8.3727
  [Batch 3400] Loss: 8.3654
  [Batch 3500] Loss: 8.3652
  [Batch 3600] Loss: 8.3432
  [Batch 3700] Loss: 8.3111
  [Batch 3800] Loss: 8.3068
  [Batch 3900] Loss: 8.2745
  [Batch 4000] Loss: 8.2569
  [Batch 4100] Loss: 8.2434
  [Batch 4200] Loss: 8.2275
[Epoch 4] Train Loss: 8.5529 | Train PPL: 5181.97 | Val PPL: 3735.75
Iteracciones: 4278
  [Batch 100] Loss: 8.1982
  [Batch 200] Loss: 8.1538
  [Batch 300] Loss: 8.1633
  [Batch 400] Loss: 8.1363
  [Batch 500] Loss: 8.1032
  [Batch 600] Loss: 8.1016
  [Batch 700] Loss: 8.0406
  [Batch 800] Loss: 8.0222
  [Batch 900] Loss: 8.0052
  [Batch 1000] Loss: 7.9958
  [Batch 1100] Loss: 7.9511
  [Batch 1200] Loss: 7.9643
  [Batch 1300] Loss: 7.9138
  [Batch 1400] Loss: 7.9325
  [Batch 1500] Loss: 7.8759
  [Batch 1600] Loss: 7.8791
  [Batch 1700] Loss: 7.8225
  [Batch 1800] Loss: 7.8040
  [Batch 1900] Loss: 7.7916
  [Batch 2000] Loss: 7.7926
  [Batch 2100] Loss: 7.7266
  [Batch 2200] Loss: 7.7283
  [Batch 2300] Loss: 7.6937
  [Batch 2400] Loss: 7.6902
  [Batch 2500] Loss: 7.6596
  [Batch 2600] Loss: 7.6270
  [Batch 2700] Loss: 7.6104
  [Batch 2800] Loss: 7.6065
  [Batch 2900] Loss: 7.5639
  [Batch 3000] Loss: 7.5082
  [Batch 3100] Loss: 7.5186
  [Batch 3200] Loss: 7.4819
  [Batch 3300] Loss: 7.4922
  [Batch 3400] Loss: 7.4588
  [Batch 3500] Loss: 7.4507
  [Batch 3600] Loss: 7.4372
  [Batch 3700] Loss: 7.4038
  [Batch 3800] Loss: 7.4043
  [Batch 3900] Loss: 7.4012
  [Batch 4000] Loss: 7.3518
  [Batch 4100] Loss: 7.3677
  [Batch 4200] Loss: 7.3178
[Epoch 5] Train Loss: 7.7446 | Train PPL: 2309.14 | Val PPL: 1443.89
Iteracciones: 4278
  [Batch 100] Loss: 7.2798
  [Batch 200] Loss: 7.2863
  [Batch 300] Loss: 7.2243
  [Batch 400] Loss: 7.2192
  [Batch 500] Loss: 7.2105
  [Batch 600] Loss: 7.1803
  [Batch 700] Loss: 7.1288
  [Batch 800] Loss: 7.1140
  [Batch 900] Loss: 7.1032
  [Batch 1000] Loss: 7.0984
  [Batch 1100] Loss: 7.1046
  [Batch 1200] Loss: 7.0946
  [Batch 1300] Loss: 7.0776
  [Batch 1400] Loss: 7.0781
  [Batch 1500] Loss: 7.0246
  [Batch 1600] Loss: 6.9856
  [Batch 1700] Loss: 6.9909
  [Batch 1800] Loss: 6.9696
  [Batch 1900] Loss: 6.9443
  [Batch 2000] Loss: 6.9561
  [Batch 2100] Loss: 6.9408
  [Batch 2200] Loss: 6.9344
  [Batch 2300] Loss: 6.9133
  [Batch 2400] Loss: 6.9033
  [Batch 2500] Loss: 6.8803
  [Batch 2600] Loss: 6.8958
  [Batch 2700] Loss: 6.8520
  [Batch 2800] Loss: 6.8421
  [Batch 2900] Loss: 6.7985
  [Batch 3000] Loss: 6.8215
  [Batch 3100] Loss: 6.8279
  [Batch 3200] Loss: 6.8077
  [Batch 3300] Loss: 6.7375
  [Batch 3400] Loss: 6.7783
  [Batch 3500] Loss: 6.7192
  [Batch 3600] Loss: 6.7370
  [Batch 3700] Loss: 6.6942
  [Batch 3800] Loss: 6.7089
  [Batch 3900] Loss: 6.6548
  [Batch 4000] Loss: 6.7127
  [Batch 4100] Loss: 6.6805
  [Batch 4200] Loss: 6.6096
[Epoch 6] Train Loss: 6.9464 | Train PPL: 1039.36 | Val PPL: 739.24
Iteracciones: 4278
  [Batch 100] Loss: 6.6297
  [Batch 200] Loss: 6.5921
  [Batch 300] Loss: 6.5919
  [Batch 400] Loss: 6.5837
  [Batch 500] Loss: 6.5662
  [Batch 600] Loss: 6.5577
  [Batch 700] Loss: 6.5308
  [Batch 800] Loss: 6.5009
  [Batch 900] Loss: 6.5290
  [Batch 1000] Loss: 6.4731
  [Batch 1100] Loss: 6.4803
  [Batch 1200] Loss: 6.4580
  [Batch 1300] Loss: 6.4682
  [Batch 1400] Loss: 6.4275
  [Batch 1500] Loss: 6.4260
  [Batch 1600] Loss: 6.4481
  [Batch 1700] Loss: 6.4257
  [Batch 1800] Loss: 6.4188
  [Batch 1900] Loss: 6.3917
  [Batch 2000] Loss: 6.3926
  [Batch 2100] Loss: 6.3514
  [Batch 2200] Loss: 6.3928
  [Batch 2300] Loss: 6.3258
  [Batch 2400] Loss: 6.3440
  [Batch 2500] Loss: 6.3350
  [Batch 2600] Loss: 6.3348
  [Batch 2700] Loss: 6.2575
  [Batch 2800] Loss: 6.2670
  [Batch 2900] Loss: 6.2891
  [Batch 3000] Loss: 6.2980
  [Batch 3100] Loss: 6.2234
  [Batch 3200] Loss: 6.2804
  [Batch 3300] Loss: 6.2585
  [Batch 3400] Loss: 6.2220
  [Batch 3500] Loss: 6.1873
  [Batch 3600] Loss: 6.2120
  [Batch 3700] Loss: 6.1937
  [Batch 3800] Loss: 6.1635
  [Batch 3900] Loss: 6.1819
  [Batch 4000] Loss: 6.1551
  [Batch 4100] Loss: 6.1832
  [Batch 4200] Loss: 6.1541
[Epoch 7] Train Loss: 6.3784 | Train PPL: 588.98 | Val PPL: 463.72
Iteracciones: 4278
  [Batch 100] Loss: 6.1364
  [Batch 200] Loss: 6.0949
  [Batch 300] Loss: 6.1083
  [Batch 400] Loss: 6.1101
  [Batch 500] Loss: 6.0876
  [Batch 600] Loss: 6.0520
  [Batch 700] Loss: 6.0742
  [Batch 800] Loss: 6.0594
  [Batch 900] Loss: 6.0054
  [Batch 1000] Loss: 6.0754
  [Batch 1100] Loss: 6.0194
  [Batch 1200] Loss: 6.0313
  [Batch 1300] Loss: 6.0013
  [Batch 1400] Loss: 6.0056
  [Batch 1500] Loss: 6.0349
  [Batch 1600] Loss: 6.0287
  [Batch 1700] Loss: 5.9783
  [Batch 1800] Loss: 5.9868
  [Batch 1900] Loss: 6.0082
  [Batch 2000] Loss: 5.9478
  [Batch 2100] Loss: 5.9108
  [Batch 2200] Loss: 5.9504
  [Batch 2300] Loss: 5.9690
  [Batch 2400] Loss: 5.9781
  [Batch 2500] Loss: 5.9451
  [Batch 2600] Loss: 5.9300
  [Batch 2700] Loss: 5.8987
  [Batch 2800] Loss: 5.9276
  [Batch 2900] Loss: 5.8890
  [Batch 3000] Loss: 5.8814
  [Batch 3100] Loss: 5.9123
  [Batch 3200] Loss: 5.8699
  [Batch 3300] Loss: 5.8710
  [Batch 3400] Loss: 5.8369
  [Batch 3500] Loss: 5.8536
  [Batch 3600] Loss: 5.8386
  [Batch 3700] Loss: 5.8816
  [Batch 3800] Loss: 5.8369
  [Batch 3900] Loss: 5.7970
  [Batch 4000] Loss: 5.8551
  [Batch 4100] Loss: 5.7488
  [Batch 4200] Loss: 5.8538
[Epoch 8] Train Loss: 5.9593 | Train PPL: 387.34 | Val PPL: 344.00
Iteracciones: 4278
  [Batch 100] Loss: 5.7781
  [Batch 200] Loss: 5.8362
  [Batch 300] Loss: 5.7966
  [Batch 400] Loss: 5.7757
  [Batch 500] Loss: 5.7931
  [Batch 600] Loss: 5.7905
  [Batch 700] Loss: 5.7694
  [Batch 800] Loss: 5.7708
  [Batch 900] Loss: 5.7738
  [Batch 1000] Loss: 5.7503
  [Batch 1100] Loss: 5.7725
  [Batch 1200] Loss: 5.7302
  [Batch 1300] Loss: 5.7353
  [Batch 1400] Loss: 5.7380
  [Batch 1500] Loss: 5.7455
  [Batch 1600] Loss: 5.7128
  [Batch 1700] Loss: 5.7466
  [Batch 1800] Loss: 5.6934
  [Batch 1900] Loss: 5.7486
  [Batch 2000] Loss: 5.6911
  [Batch 2100] Loss: 5.7668
  [Batch 2200] Loss: 5.7356
  [Batch 2300] Loss: 5.6665
  [Batch 2400] Loss: 5.7002
  [Batch 2500] Loss: 5.6849
  [Batch 2600] Loss: 5.7347
  [Batch 2700] Loss: 5.6939
  [Batch 2800] Loss: 5.6819
  [Batch 2900] Loss: 5.6678
  [Batch 3000] Loss: 5.6889
  [Batch 3100] Loss: 5.6706
  [Batch 3200] Loss: 5.6425
  [Batch 3300] Loss: 5.5771
  [Batch 3400] Loss: 5.5543
  [Batch 3500] Loss: 5.6177
  [Batch 3600] Loss: 5.6092
  [Batch 3700] Loss: 5.6313
  [Batch 3800] Loss: 5.6131
  [Batch 3900] Loss: 5.6667
  [Batch 4000] Loss: 5.6050
  [Batch 4100] Loss: 5.6392
  [Batch 4200] Loss: 5.6192
[Epoch 9] Train Loss: 5.6918 | Train PPL: 296.42 | Val PPL: 288.88
Iteracciones: 4278
  [Batch 100] Loss: 5.5647
  [Batch 200] Loss: 5.6249
  [Batch 300] Loss: 5.5705
  [Batch 400] Loss: 5.5563
  [Batch 500] Loss: 5.5190
  [Batch 600] Loss: 5.5797
  [Batch 700] Loss: 5.5864
  [Batch 800] Loss: 5.5599
  [Batch 900] Loss: 5.6021
  [Batch 1000] Loss: 5.5708
  [Batch 1100] Loss: 5.5226
  [Batch 1200] Loss: 5.5563
  [Batch 1300] Loss: 5.5108
  [Batch 1400] Loss: 5.5276
  [Batch 1500] Loss: 5.5202
  [Batch 1600] Loss: 5.5582
  [Batch 1700] Loss: 5.5693
  [Batch 1800] Loss: 5.4927
  [Batch 1900] Loss: 5.4791
  [Batch 2000] Loss: 5.5335
  [Batch 2100] Loss: 5.5223
  [Batch 2200] Loss: 5.5431
  [Batch 2300] Loss: 5.4453
  [Batch 2400] Loss: 5.5061
  [Batch 2500] Loss: 5.4906
  [Batch 2600] Loss: 5.4401
  [Batch 2700] Loss: 5.5018
  [Batch 2800] Loss: 5.4229
  [Batch 2900] Loss: 5.5155
  [Batch 3000] Loss: 5.4907
  [Batch 3100] Loss: 5.5019
  [Batch 3200] Loss: 5.5210
  [Batch 3300] Loss: 5.4430
  [Batch 3400] Loss: 5.4667
  [Batch 3500] Loss: 5.4573
  [Batch 3600] Loss: 5.4361
  [Batch 3700] Loss: 5.4675
  [Batch 3800] Loss: 5.3749
  [Batch 3900] Loss: 5.4074
  [Batch 4000] Loss: 5.4364
  [Batch 4100] Loss: 5.4178
  [Batch 4200] Loss: 5.4707
[Epoch 10] Train Loss: 5.5103 | Train PPL: 247.24 | Val PPL: 250.98
Iteracciones: 4278
  [Batch 100] Loss: 5.3741
  [Batch 200] Loss: 5.4937
  [Batch 300] Loss: 5.3902
  [Batch 400] Loss: 5.4472
  [Batch 500] Loss: 5.4509
  [Batch 600] Loss: 5.3657
  [Batch 700] Loss: 5.3597
  [Batch 800] Loss: 5.3979
  [Batch 900] Loss: 5.3962
  [Batch 1000] Loss: 5.3945
  [Batch 1100] Loss: 5.4133
  [Batch 1200] Loss: 5.3723
  [Batch 1300] Loss: 5.3543
  [Batch 1400] Loss: 5.3677
  [Batch 1500] Loss: 5.3513
  [Batch 1600] Loss: 5.4104
  [Batch 1700] Loss: 5.3378
  [Batch 1800] Loss: 5.3837
  [Batch 1900] Loss: 5.3981
  [Batch 2000] Loss: 5.3626
  [Batch 2100] Loss: 5.3183
  [Batch 2200] Loss: 5.3779
  [Batch 2300] Loss: 5.3189
  [Batch 2400] Loss: 5.3527
  [Batch 2500] Loss: 5.2980
  [Batch 2600] Loss: 5.3592
  [Batch 2700] Loss: 5.3540
  [Batch 2800] Loss: 5.3367
  [Batch 2900] Loss: 5.3173
  [Batch 3000] Loss: 5.3304
  [Batch 3100] Loss: 5.3229
  [Batch 3200] Loss: 5.3037
  [Batch 3300] Loss: 5.3256
  [Batch 3400] Loss: 5.2629
  [Batch 3500] Loss: 5.3097
  [Batch 3600] Loss: 5.2991
  [Batch 3700] Loss: 5.2486
  [Batch 3800] Loss: 5.2705
  [Batch 3900] Loss: 5.3328
  [Batch 4000] Loss: 5.3251
  [Batch 4100] Loss: 5.2483
  [Batch 4200] Loss: 5.2732
[Epoch 11] Train Loss: 5.3595 | Train PPL: 212.61 | Val PPL: 220.95
Iteracciones: 4278
  [Batch 100] Loss: 5.2923
  [Batch 200] Loss: 5.2276
  [Batch 300] Loss: 5.3080
  [Batch 400] Loss: 5.2801
  [Batch 500] Loss: 5.2483
  [Batch 600] Loss: 5.2718
  [Batch 700] Loss: 5.2961
  [Batch 800] Loss: 5.3391
  [Batch 900] Loss: 5.2803
  [Batch 1000] Loss: 5.1932
  [Batch 1100] Loss: 5.2926
  [Batch 1200] Loss: 5.2009
  [Batch 1300] Loss: 5.3017
  [Batch 1400] Loss: 5.2640
  [Batch 1500] Loss: 5.2839
  [Batch 1600] Loss: 5.1862
  [Batch 1700] Loss: 5.2640
  [Batch 1800] Loss: 5.2087
  [Batch 1900] Loss: 5.2821
  [Batch 2000] Loss: 5.2496
  [Batch 2100] Loss: 5.2894
  [Batch 2200] Loss: 5.2361
  [Batch 2300] Loss: 5.1792
  [Batch 2400] Loss: 5.2058
  [Batch 2500] Loss: 5.2151
  [Batch 2600] Loss: 5.1945
  [Batch 2700] Loss: 5.2059
  [Batch 2800] Loss: 5.2300
  [Batch 2900] Loss: 5.2656
  [Batch 3000] Loss: 5.1553
  [Batch 3100] Loss: 5.2312
  [Batch 3200] Loss: 5.1619
  [Batch 3300] Loss: 5.1781
  [Batch 3400] Loss: 5.1318
  [Batch 3500] Loss: 5.2126
  [Batch 3600] Loss: 5.2058
  [Batch 3700] Loss: 5.1929
  [Batch 3800] Loss: 5.1257
  [Batch 3900] Loss: 5.1788
  [Batch 4000] Loss: 5.1917
  [Batch 4100] Loss: 5.1264
  [Batch 4200] Loss: 5.1739
[Epoch 12] Train Loss: 5.2193 | Train PPL: 184.81 | Val PPL: 196.64
Iteracciones: 4278
  [Batch 100] Loss: 5.1235
  [Batch 200] Loss: 5.1110
  [Batch 300] Loss: 5.1064
  [Batch 400] Loss: 5.1425
  [Batch 500] Loss: 5.1388
  [Batch 600] Loss: 5.1260
  [Batch 700] Loss: 5.1072
  [Batch 800] Loss: 5.0703
  [Batch 900] Loss: 5.1186
  [Batch 1000] Loss: 5.0994
  [Batch 1100] Loss: 5.0327
  [Batch 1200] Loss: 5.0699
  [Batch 1300] Loss: 5.1682
  [Batch 1400] Loss: 5.1161
  [Batch 1500] Loss: 5.0984
  [Batch 1600] Loss: 5.1956
  [Batch 1700] Loss: 5.1430
  [Batch 1800] Loss: 5.0817
  [Batch 1900] Loss: 5.1645
  [Batch 2000] Loss: 5.0992
  [Batch 2100] Loss: 5.1442
  [Batch 2200] Loss: 5.0867
  [Batch 2300] Loss: 5.0147
  [Batch 2400] Loss: 5.0647
  [Batch 2500] Loss: 5.0834
  [Batch 2600] Loss: 5.1160
  [Batch 2700] Loss: 5.0529
  [Batch 2800] Loss: 5.0424
  [Batch 2900] Loss: 5.0807
  [Batch 3000] Loss: 5.0682
  [Batch 3100] Loss: 5.0309
  [Batch 3200] Loss: 5.0800
  [Batch 3300] Loss: 5.0124
  [Batch 3400] Loss: 5.0721
  [Batch 3500] Loss: 5.0299
  [Batch 3600] Loss: 5.0355
  [Batch 3700] Loss: 5.0301
  [Batch 3800] Loss: 5.0907
  [Batch 3900] Loss: 5.0518
  [Batch 4000] Loss: 5.0355
  [Batch 4100] Loss: 5.0002
  [Batch 4200] Loss: 5.0150
[Epoch 13] Train Loss: 5.0917 | Train PPL: 162.67 | Val PPL: 177.45
Iteracciones: 4278
  [Batch 100] Loss: 5.0067
  [Batch 200] Loss: 5.0320
  [Batch 300] Loss: 5.0525
  [Batch 400] Loss: 5.0076
  [Batch 500] Loss: 5.0638
  [Batch 600] Loss: 4.9565
  [Batch 700] Loss: 5.0274
  [Batch 800] Loss: 5.0441
  [Batch 900] Loss: 5.0090
  [Batch 1000] Loss: 5.0626
  [Batch 1100] Loss: 5.0636
  [Batch 1200] Loss: 4.9847
  [Batch 1300] Loss: 4.9532
  [Batch 1400] Loss: 5.0140
  [Batch 1500] Loss: 4.9859
  [Batch 1600] Loss: 5.0118
  [Batch 1700] Loss: 4.9756
  [Batch 1800] Loss: 4.9379
  [Batch 1900] Loss: 4.9613
  [Batch 2000] Loss: 5.0110
  [Batch 2100] Loss: 4.9789
  [Batch 2200] Loss: 4.9540
  [Batch 2300] Loss: 5.0000
  [Batch 2400] Loss: 4.9860
  [Batch 2500] Loss: 4.9664
  [Batch 2600] Loss: 4.9221
  [Batch 2700] Loss: 4.9903
  [Batch 2800] Loss: 4.9830
  [Batch 2900] Loss: 4.8772
  [Batch 3000] Loss: 4.9409
  [Batch 3100] Loss: 4.9500
  [Batch 3200] Loss: 4.9443
  [Batch 3300] Loss: 4.9894
  [Batch 3400] Loss: 4.9453
  [Batch 3500] Loss: 4.9572
  [Batch 3600] Loss: 4.9732
  [Batch 3700] Loss: 4.8764
  [Batch 3800] Loss: 4.9617
  [Batch 3900] Loss: 4.9568
  [Batch 4000] Loss: 4.9828
  [Batch 4100] Loss: 4.8821
  [Batch 4200] Loss: 5.0153
[Epoch 14] Train Loss: 4.9786 | Train PPL: 145.27 | Val PPL: 162.43
Iteracciones: 4278
  [Batch 100] Loss: 4.9036
  [Batch 200] Loss: 4.9604
  [Batch 300] Loss: 4.8834
  [Batch 400] Loss: 4.8467
  [Batch 500] Loss: 4.9238
  [Batch 600] Loss: 4.9544
  [Batch 700] Loss: 4.9138
  [Batch 800] Loss: 4.9997
  [Batch 900] Loss: 4.8895
  [Batch 1000] Loss: 4.9069
  [Batch 1100] Loss: 4.9238
  [Batch 1200] Loss: 4.9074
  [Batch 1300] Loss: 4.9190
  [Batch 1400] Loss: 4.8199
  [Batch 1500] Loss: 4.7948
  [Batch 1600] Loss: 4.9095
  [Batch 1700] Loss: 4.8318
  [Batch 1800] Loss: 4.9319
  [Batch 1900] Loss: 4.8457
  [Batch 2000] Loss: 4.8964
  [Batch 2100] Loss: 4.8509
  [Batch 2200] Loss: 4.9123
  [Batch 2300] Loss: 4.8308
  [Batch 2400] Loss: 4.9029
  [Batch 2500] Loss: 4.8572
  [Batch 2600] Loss: 4.8290
  [Batch 2700] Loss: 4.8645
  [Batch 2800] Loss: 4.9320
  [Batch 2900] Loss: 4.8432
  [Batch 3000] Loss: 4.8484
  [Batch 3100] Loss: 4.8229
  [Batch 3200] Loss: 4.8446
  [Batch 3300] Loss: 4.8547
  [Batch 3400] Loss: 4.8489
  [Batch 3500] Loss: 4.8979
  [Batch 3600] Loss: 4.8577
  [Batch 3700] Loss: 4.8719
  [Batch 3800] Loss: 4.8182
  [Batch 3900] Loss: 4.8805
  [Batch 4000] Loss: 4.9218
  [Batch 4100] Loss: 4.8120
  [Batch 4200] Loss: 4.8601
[Epoch 15] Train Loss: 4.8794 | Train PPL: 131.55 | Val PPL: 150.69
Iteracciones: 4278
  [Batch 100] Loss: 4.8515
  [Batch 200] Loss: 4.8103
  [Batch 300] Loss: 4.9074
  [Batch 400] Loss: 4.7689
  [Batch 500] Loss: 4.8396
  [Batch 600] Loss: 4.7753
  [Batch 700] Loss: 4.8800
  [Batch 800] Loss: 4.7873
  [Batch 900] Loss: 4.7776
  [Batch 1000] Loss: 4.8309
  [Batch 1100] Loss: 4.7891
  [Batch 1200] Loss: 4.8331
  [Batch 1300] Loss: 4.8576
  [Batch 1400] Loss: 4.8741
  [Batch 1500] Loss: 4.7616
  [Batch 1600] Loss: 4.8168
  [Batch 1700] Loss: 4.8006
  [Batch 1800] Loss: 4.7667
  [Batch 1900] Loss: 4.8397
  [Batch 2000] Loss: 4.7405
  [Batch 2100] Loss: 4.7706
  [Batch 2200] Loss: 4.7784
  [Batch 2300] Loss: 4.8010
  [Batch 2400] Loss: 4.7858
  [Batch 2500] Loss: 4.7672
  [Batch 2600] Loss: 4.7619
  [Batch 2700] Loss: 4.7777
  [Batch 2800] Loss: 4.7005
  [Batch 2900] Loss: 4.7691
  [Batch 3000] Loss: 4.8042
  [Batch 3100] Loss: 4.7391
  [Batch 3200] Loss: 4.7383
  [Batch 3300] Loss: 4.7592
  [Batch 3400] Loss: 4.7989
  [Batch 3500] Loss: 4.7042
  [Batch 3600] Loss: 4.7625
  [Batch 3700] Loss: 4.7883
  [Batch 3800] Loss: 4.7393
  [Batch 3900] Loss: 4.8066
  [Batch 4000] Loss: 4.7741
  [Batch 4100] Loss: 4.7100
  [Batch 4200] Loss: 4.7637
[Epoch 16] Train Loss: 4.7929 | Train PPL: 120.65 | Val PPL: 141.61
Iteracciones: 4278
  [Batch 100] Loss: 4.7256
  [Batch 200] Loss: 4.7780
  [Batch 300] Loss: 4.8216
  [Batch 400] Loss: 4.7486
  [Batch 500] Loss: 4.7250
  [Batch 600] Loss: 4.7488
  [Batch 700] Loss: 4.7216
  [Batch 800] Loss: 4.8132
  [Batch 900] Loss: 4.7452
  [Batch 1000] Loss: 4.7029
  [Batch 1100] Loss: 4.7180
  [Batch 1200] Loss: 4.7658
  [Batch 1300] Loss: 4.7534
  [Batch 1400] Loss: 4.7270
  [Batch 1500] Loss: 4.7381
  [Batch 1600] Loss: 4.6399
  [Batch 1700] Loss: 4.7892
  [Batch 1800] Loss: 4.7012
  [Batch 1900] Loss: 4.7637
  [Batch 2000] Loss: 4.8271
  [Batch 2100] Loss: 4.7351
  [Batch 2200] Loss: 4.7476
  [Batch 2300] Loss: 4.7436
  [Batch 2400] Loss: 4.6976
  [Batch 2500] Loss: 4.7370
  [Batch 2600] Loss: 4.6979
  [Batch 2700] Loss: 4.7319
  [Batch 2800] Loss: 4.6224
  [Batch 2900] Loss: 4.7270
  [Batch 3000] Loss: 4.7380
  [Batch 3100] Loss: 4.7065
  [Batch 3200] Loss: 4.6822
  [Batch 3300] Loss: 4.6639
  [Batch 3400] Loss: 4.6974
  [Batch 3500] Loss: 4.7130
  [Batch 3600] Loss: 4.7210
  [Batch 3700] Loss: 4.7240
  [Batch 3800] Loss: 4.6703
  [Batch 3900] Loss: 4.6392
  [Batch 4000] Loss: 4.6484
  [Batch 4100] Loss: 4.7511
  [Batch 4200] Loss: 4.6707
[Epoch 17] Train Loss: 4.7179 | Train PPL: 111.94 | Val PPL: 134.49
Iteracciones: 4278
  [Batch 100] Loss: 4.6293
  [Batch 200] Loss: 4.6503
  [Batch 300] Loss: 4.7172
  [Batch 400] Loss: 4.6657
  [Batch 500] Loss: 4.6532
  [Batch 600] Loss: 4.6770
  [Batch 700] Loss: 4.6757
  [Batch 800] Loss: 4.5960
  [Batch 900] Loss: 4.7067
  [Batch 1000] Loss: 4.6446
  [Batch 1100] Loss: 4.6452
  [Batch 1200] Loss: 4.6114
  [Batch 1300] Loss: 4.6656
  [Batch 1400] Loss: 4.6519
  [Batch 1500] Loss: 4.6605
  [Batch 1600] Loss: 4.6289
  [Batch 1700] Loss: 4.6907
  [Batch 1800] Loss: 4.6646
  [Batch 1900] Loss: 4.6631
  [Batch 2000] Loss: 4.6400
  [Batch 2100] Loss: 4.6794
  [Batch 2200] Loss: 4.6786
  [Batch 2300] Loss: 4.5914
  [Batch 2400] Loss: 4.6232
  [Batch 2500] Loss: 4.6525
  [Batch 2600] Loss: 4.6642
  [Batch 2700] Loss: 4.6651
  [Batch 2800] Loss: 4.6203
  [Batch 2900] Loss: 4.6160
  [Batch 3000] Loss: 4.6191
  [Batch 3100] Loss: 4.5729
  [Batch 3200] Loss: 4.5730
  [Batch 3300] Loss: 4.6666
  [Batch 3400] Loss: 4.5743
  [Batch 3500] Loss: 4.6488
  [Batch 3600] Loss: 4.6331
  [Batch 3700] Loss: 4.6269
  [Batch 3800] Loss: 4.6054
  [Batch 3900] Loss: 4.5663
  [Batch 4000] Loss: 4.6333
  [Batch 4100] Loss: 4.5821
  [Batch 4200] Loss: 4.5784
[Epoch 18] Train Loss: 4.6520 | Train PPL: 104.80 | Val PPL: 128.90
Iteracciones: 4278
  [Batch 100] Loss: 4.5728
  [Batch 200] Loss: 4.6022
  [Batch 300] Loss: 4.6308
  [Batch 400] Loss: 4.6104
  [Batch 500] Loss: 4.5608
  [Batch 600] Loss: 4.6154
  [Batch 700] Loss: 4.5708
  [Batch 800] Loss: 4.6481
  [Batch 900] Loss: 4.6072
  [Batch 1000] Loss: 4.5976
  [Batch 1100] Loss: 4.6052
  [Batch 1200] Loss: 4.6491
  [Batch 1300] Loss: 4.6472
  [Batch 1400] Loss: 4.6443
  [Batch 1500] Loss: 4.5685
  [Batch 1600] Loss: 4.6052
  [Batch 1700] Loss: 4.6216
  [Batch 1800] Loss: 4.5952
  [Batch 1900] Loss: 4.6094
  [Batch 2000] Loss: 4.6824
  [Batch 2100] Loss: 4.6048
  [Batch 2200] Loss: 4.5675
  [Batch 2300] Loss: 4.5941
  [Batch 2400] Loss: 4.5621
  [Batch 2500] Loss: 4.6759
  [Batch 2600] Loss: 4.5307
  [Batch 2700] Loss: 4.5672
  [Batch 2800] Loss: 4.5247
  [Batch 2900] Loss: 4.5385
  [Batch 3000] Loss: 4.5660
  [Batch 3100] Loss: 4.5573
  [Batch 3200] Loss: 4.5582
  [Batch 3300] Loss: 4.5470
  [Batch 3400] Loss: 4.6324
  [Batch 3500] Loss: 4.5792
  [Batch 3600] Loss: 4.5432
  [Batch 3700] Loss: 4.5101
  [Batch 3800] Loss: 4.5866
  [Batch 3900] Loss: 4.5888
  [Batch 4000] Loss: 4.5677
  [Batch 4100] Loss: 4.4625
  [Batch 4200] Loss: 4.6150
[Epoch 19] Train Loss: 4.5928 | Train PPL: 98.77 | Val PPL: 124.23
Iteracciones: 4278
  [Batch 100] Loss: 4.5618
  [Batch 200] Loss: 4.5359
  [Batch 300] Loss: 4.5917
  [Batch 400] Loss: 4.6227
  [Batch 500] Loss: 4.5047
  [Batch 600] Loss: 4.5773
  [Batch 700] Loss: 4.6082
  [Batch 800] Loss: 4.5990
  [Batch 900] Loss: 4.5265
  [Batch 1000] Loss: 4.5595
  [Batch 1100] Loss: 4.5342
  [Batch 1200] Loss: 4.5931
  [Batch 1300] Loss: 4.5633
  [Batch 1400] Loss: 4.5717
  [Batch 1500] Loss: 4.5885
  [Batch 1600] Loss: 4.5599
  [Batch 1700] Loss: 4.4921
  [Batch 1800] Loss: 4.5189
  [Batch 1900] Loss: 4.6067
  [Batch 2000] Loss: 4.5589
  [Batch 2100] Loss: 4.5308
  [Batch 2200] Loss: 4.5733
  [Batch 2300] Loss: 4.5823
  [Batch 2400] Loss: 4.5038
  [Batch 2500] Loss: 4.5764
  [Batch 2600] Loss: 4.4961
  [Batch 2700] Loss: 4.5779
  [Batch 2800] Loss: 4.4694
  [Batch 2900] Loss: 4.5846
  [Batch 3000] Loss: 4.5450
  [Batch 3100] Loss: 4.5999
  [Batch 3200] Loss: 4.5318
  [Batch 3300] Loss: 4.5176
  [Batch 3400] Loss: 4.4979
  [Batch 3500] Loss: 4.5568
  [Batch 3600] Loss: 4.4499
  [Batch 3700] Loss: 4.5383
  [Batch 3800] Loss: 4.4574
  [Batch 3900] Loss: 4.5462
  [Batch 4000] Loss: 4.5109
  [Batch 4100] Loss: 4.5622
  [Batch 4200] Loss: 4.5765
[Epoch 20] Train Loss: 4.5385 | Train PPL: 93.55 | Val PPL: 120.28
Entrenamiento finalizado.
Best Train Loss: 4.5385 | Best Train PPL: 93.55
